# **统计学习方法**
## **第1章&nbsp;&nbsp;统计学习及监督学习概述**

<br>

**导论：**
- 1.1节叙述统计学习或机器学习的定义、研究对象与方法；
- 1.2节叙述统计学习的分类，基本分类是监督学习、无监督学习、强化学习；
- 1.3节叙述统计学习方法的三要素；模型、策略和算法；
- 1.4节至1.7节相继介绍监督学习的几个重要概念，包括模型评估与模型选择、正则化与交叉验证、学习的泛化能力、生成模型与判别模型；
 - 1.8节介绍监督学习的应用：分类问题，标注问题与回归问题。


<p align="center">
        <img src="http://115.159.24.45:3000/statistical_learning/pic/Fig1.png" width="60%"/>
</p>
<p align="center">总体学习框架图</p>


### **1.1&nbsp;&nbsp;统计学习**

#### **1.&nbsp;&nbsp;统计学习特点**
（1）统计学习以计算机及网络为平台，是建立在计算机及网络上的；\
（2）统计学习以数据为研究对象，是数据驱动的学科；\
（3）统计学习的目的是对数据进行预测与分析；\
（4）统计学习以方法为中心，统计学习方法构建模型并应用模型进行预测与分析；\
（5）统计学习是概率论、统计学、信息论、计算理论、最优化理论及计算机科学等多个领域的交叉学科，并且在发展中逐步形成独自的理论体系与方法论。
#### **2.&nbsp;&nbsp;统计学习的对象**
数据。
#### **3.&nbsp;&nbsp;统计学习的目的**
统计学习用于对数据的预测与分析，特别是对**未知新数据**的预测与分析。对数据的预测与分析是通过构建概率统计模型实现的。统计学习总的目标就是考虑学习什么样的模型和如何学习模型，以使模型能对数据进行准确的预测与分析，同时也要考虑尽可能地提高学习效率。
#### **4.&nbsp;&nbsp;统计学习的方法**

统计学习的方法是基于数据构建概率统计模型从而对数据进行预测与分析。统计学习由监督学习（supervised learning）、无监督学习（unsupervised learning）和强化学习（reinforcement learning） 等组成。

统计学习方法可以概括如下：
- 从给定的、有限的、用于学习的训练数据（training data）集合出发，假设数据是独立同分布产生的；
- 并且假设要学习的模型属于某个函数的集合，称为假设空间（hypothesis space）；
- 应用某个评价准则（evaluation criterion），从假设空间中选取一个最优模型，使它对己知的训练数据及未知的测试数（test data）在给定的评价准则下有最优的预测，最优模型的选取由算法实现。
- 这样，统计学习方法包括模型的假设空间、模型选择的准则以及模型学习的算法。称其为统计学习方法的三要素，简称为模型 （model）、策略 （strategy）和算法（algorithm）。

实现统计学习的步骤：
1. 得到一个有限的训练数据集合（训练集）
2. 确定模型的假设空间，也就是所有备选模型（模型结构）
3. 确认模型学习的准则，即学习的策略（**怎么学习，设计cost funtion？**）
4. 实现求解最优模型的算法（**如何求解，优化器？**）
5. 通过学习方法选择最优模型
6. 利用学习的最优模型对新数据进行预测或分析（预测）

### **1.2&nbsp;&nbsp;统计学习的分类**
<p align="center">
        <img src="http://115.159.24.45:3000/statistical_learning/pic/Fig2.png" width="90%"/>
</p>
<p align="center">统计学习的分类总体框架图</p>


#### **1.2.1 基本分类**
1. **监督学习**
> 监督学习 (supervised learning) 是指从标注数据中学习预测模型的机器学习问题。标注数据表示输入输出的对应关系，预测模型对给定的输入产生相应的输出。监督学习的本质是学习输入到输出的映射的统计规律。

- **输入空间与输出空间**
> 在监督学习中，将输入与输出所有可能取值的集合分别称为输入空间 (input space) 与输出空间 (output space) 。输入与输出空间可以是有限元素的集合，也可以是整个欧氏空间。输入空间与输出空间可以是同一个空间，也可以是不同的空间;但通常输出空间远远小于输入空间。

- **特征空间**
> 每个具体的输入是一个实例(instance) ，通常由特征向量 (feature vector) 表示。这时，所有特征向量存在的空间称为特征空间 (feature space) 。特征空间的每一维对应于 个特征。有时假设输入空间与特征空间为相同的空间，对它们不予区分；有时假设输入空间与特征空间为不同的空间，将实例从输入空间映射到特征空间。模型实际上都是定义在特征空间上的。

在监督学习中，将输入与输出看作是定义在输入(特征〉空间与输出空间上的随机变量的取值。输入输出变量用大写字母表示，习惯上输入变量写作$X$输出变量写$Y$。输入输出变量的取值用小写字母表示，输入变量的取值写作$x$输出变量的取值写作$Y$。变量可以是标量或向量，都用相同类型字母表示。除特别声明外，向量均为列向量 。输入实例$x$的特征向量记作

$$x=(x^{(1)},x^{(2)},x^{(3)},...,x^{(n)}) ^T$$

$x^{(i)}$表示$x$的第$i$个特征。注意$x^{(i)}$与$x_i$ 不同，通常用 $x_i$ 表示多个输入变量中的第$i$个变量，即
$$x=(x^{(1)}_i,x^{(2)}_i,x^{(3)}_i,...,x^{(n)}_i) ^T$$

监督学习从训练数据 (training data) 合中学习模型，对测试数据 (test data) 进行预测。训练数据由输入(或特征向量)与输出对组成，训练集通常表示为
$$T=\{(x_1,y_1),(x_1,y_1),(x_1,y_1),...,(x_N,y_N)\}$$
测试数据也由输入与输出对组成 输入与输出对又称为样本 (sample) 或样本点。


监督学习利用训练数据集学习一个模型，再用模型对测试样本集进行预测。由于在这个过程中需要标注的训练数据集，而标注的训练数据集往往是人工给出的 ，所以称为监督学习。监督学习分为学习和预测两个过程，由学习系统与预测系统完成，可用下图表示。
<p align="center">
        <img src="http://115.159.24.45:3000/statistical_learning/pic/Fig3.png" width="40%"/>
</p>

监督学习分为学习和预测两个过程，由学习系统与预测系统完成。在学习过程中，学习系统利用给定的训练数据集，通过学习(或训练)得到一个模型，表示为条件概率分布$\hat{P}(Y|X)$或决策函数$Y=\hat{f}(X)$。条件概率分布$\hat{P}(Y|X)$或决策函数$Y=\hat{f}(X)$描述输入与输出随机变量之间的映射关系。在预测过程中，预测系统对于给定的测试样本集中的输入$x_{N+1}$由模型$y_{N+1}=argmax_y\hat{P}(y|x_{N+1})$或$y_{N+1}=\hat{f}(y|x_{N+1})$给出相应的输出$y_{N+1}$。

2. **无监督学习**

> 无监督学习(unsupervised learning) 是指从无标注数据中学习预测模型的机器学习问题。无标注数据是自然得到的数据，预测模型表示数据的类别、转换或概率。

无监督学习的本质是学习数据中的统计规律或潜在结构。模型的输入与输出的所有可能取值的集合分别称为输入空间与输出空间。输入空间与输出空间可以是有限元素集合，也可以是欧氏空间。每个输入是一个实例，由特征向量表示。每一个输出是对输入的分析结果，由输入的类别、转换或概率表示。模型可以实现对数据的聚类、降维或概率估计。

假设$\chi$是输入空间，$\Zeta$是隐式结构空间 。要学习的模型可以表示为函数$z=g(X)$条件概率分布 $P(z|x)$ 或者条件概率分布 $P(x|z)$ 的形式，其中$x\in\chi$是输入，$y_i\in {\rm Y}$是输出。包含所有可能的模型的集合称为假设空间。无监督学习旨在从假设空间中选出在给定评价标准下的最优模型。

无监督学习通常使用大量的无标注数据学习或训练，每个样本是一个实例。训练数据表示为$U=\{x_1,x_2,...,x_N\}$，其中$x_i,i=1,2,...,N$是样本。

无监督学习可以用于对己有数据的分析，也可以用于对未来数据的预测。分析时使用学习得到的模型，即函数 $z = \hat g(x)$ 条件概率分布$\hat P(z|x)$或者条件概率分布 $\hat P(x|z)$ 。预测时，和监督学习有类似的流程。在学习过程中，学习系统从训练数据集学习，得到一个最优模型，表示为函数 $Z=\hat g(x)$ 条件概率分布$\hat P(z|x)$ 或者条件概率分布$\hat P(z|x)$ 。在预测过程中，预测系统对于给定的输入$ x_{N+l}$，由模型$Z_{N+l} = \hat g(X_{N+1})$或$ Z_{N+1} = argmax_z\hat P(z|x_{N+1})$ 给出相应的输出$z_{N+1}$进行聚类或降维，或者由模型$\hat P(x|z)$给出输入的概率$\hat P(x_{N+1}|z_{N+1})$进行概率估计。

<p align="center">
        <img src="http://115.159.24.45:3000/statistical_learning/pic/Fig4.png" width="50%"/>
</p>

3. **强化学习**

4. **半监督学习与主动学习**

半监督学习 (semi-supervised learning) 是指利用标注数据和未标注数据学习预测模型的机器学习问题。通常有少量标注数据、大量未标注数据，因为标注数据的构建往往需要人工，成本较高，未标注数据的收集不需太多成本。半监督学习旨在利用未标注数据中的信息，辅助标注数据，进行监督学习，以较低的成本达到较好的学习效果。

主动学习 (active learning) 是指机器不断主动给出实例让教师进行标注，然后利用标注数据学习预测模型的机器学习问题。通常的监督学习使用给定的标注数据，往往是随机得到的 ，可以看作是"被动学习" 主动学习的目标是找出对学习最有帮助的实例让教师标注，以较小的标注代价，达到较好的学习效果。

#### **1.2.2 按照模型分类**

1. **概率模型与非概率模型**

在监督学习中，概率模型取条件概率分布形式 $P(y|x)$，非概率模型取函数形式 $y=f(x)$ 其中$x$是输入，$y$是输出。在无监督学习中，概率模型取条件概率分布形式 $P(z|x)$或 $P(x|z)$，非概率模型取函数形式 $z = g(x)$，其中$x$是输入，$z$是输出。在监督学习中，概率模型是生成模型，非概率模型是判别模型。

<p align="center">
        <img src="http://115.159.24.45:3000/statistical_learning/pic/Fig5.png" width="50%"/>
</p>

条件概率分布$P(y|x)$和函数$y = f(x)$ 可以相互转化(条件概率分布$ P(z|x)$函数 $z = g(x)$ 同样可以) 。具体地，条件概率分布最大后得到函数，函数归一化后得到条件概率分布。

所以，概率模型和非概率模型的区别不在于输入与输出之间的映射关系，而在于模型的内在结构。概率模型一定可以表示为联合概率分布的形式，其中的变量表示输入、输出、隐变量甚至参数。而针对非概率模型则不一定存在这样的联合概率分布。

概率模型的代表是概率图模型 (probabilistic graphical model) ，概率图模型是联合概率分布由有向图或者无向图表示的概率模型，而联合概率分布可以根据图的结构分解为因子乘积的形式。贝叶斯网络、马尔可夫随机场、条件随机场是概率图模型。无论模型如何复杂，均可以用最基本的加法规则和乘法规则进行概率推理。

$$加法规则: P(x)=\sum_{y}^{}P(x,y) $$
$$乘法规则: P(x,y)=P(y|x)P(x) $$

2. **线性模型与非线性模型**

统计学习模型，特别是非概率模型，可以分为线性模型(linear mode)和非线性模型 (non-linear model) 。如果函数 $f(x) = g(x)$或$z = g(x)$ 是线性函数，则称模型是线性模型，否则称模型是非线性模型。

<p align="center">
        <img src="http://115.159.24.45:3000/statistical_learning/pic/Fig6.png" width="50%"/>
</p>

3. **参数化模型与非参数化模型**

统计学习模型又可以分为参数化模型 (parametric model)和非参数化模型 (nonparametric model)。参数化模型假设模型参数的维度固定，模型可以由有限维参数完全刻画:非参数化模型假设模型参数的维度不固定或者说无穷大，随着训练数据量的增加而不断增大。

<p align="center">
        <img src="http://115.159.24.45:3000/statistical_learning/pic/Fig7.png" width="50%"/>
</p>


#### **1.2.3 按算法分类**

统计学习根据算法，可以分为在线学习 (online learning) 与批量学习 (batch learning) 。在线学习是指每次接受一个样本，进行预测，之后学习模型，并不断重复该操作的机器学习。与之对应，批量学习次接受所有数据，学习模型，之后进行预测。有些实际应用的场景要求学习必须是在线的。比如，数据依次达到无法存储，系统需要及时做出处理:数据规模很大，不可能 次处理所有数据:数据的模式随时间动态变化，需要算法快速适应新的模式(不满足独立同分布假设)。

在线学习可以是监督学习，也可以是无监督学习，强化学习本身就拥有在线学习的特点。以下只考虑在线的监督学习。

学习和预测在一个系统，每次接受一个输入$x_t$，用己有模型给出预测$\hat f(x_t)$之后得到相应的反馈，即该输入对应的输出$y_t$；系统用损失函数计算两者的差异，更新模型；并不断重复以上操作。
<p align="center">
        <img src="http://115.159.24.45:3000/statistical_learning/pic/Fig8.png" width="60%"/>
</p>

在线学习通常比批量学习更难，很难学到预测准确率更高的模型，因为每次模型更新中，可利用的数据有限。

#### **1.2.4 按技巧分类**

1. **贝叶斯学习**

贝叶斯学习 (Bayesian learning) ，又称为贝叶斯推理(Bayesian inference) ，是统计学、机器学习中重要的方法。其主要想法是，在概率模型的学习和推理中，利用贝叶斯定理，计算在给定数据条件下模型的条件概率，即后验概率，并应用这个原理进行模型的估计，以及对数据的预测。将模型、未观测要素及其参数用变量表示，使用模型的先验分布是贝叶斯学习的特点。贝叶斯学习中也使用基本概率公式，朴素贝叶斯、潜在狄利克雷分配的学习属于贝叶斯学习。

假设随机变量$D$表示数据，随机变量$\theta $表示模型参数。根据贝叶斯定理，可以用以下公式计算后验概率 $P(\theta |D)$:
$$P(\theta |D)=\frac{P(\theta )P(D|\theta )}{P(D)}$$

其中，$P(\theta )$是先验概率，$P(D|\theta )$是似然函数。

模型估计时，估计整个后验概率分布 $P(\theta|D)$。如果需要给出一个模型，通常取后验概率最大的模型。

预测时，计算数据对后验概率分布的期望值:
$$P(x|D)=\int P(x|\theta ,D)P(\theta |D)d\theta $$

贝叶斯估计与极大似然估计在思想上有很大的不同，代表着统计学中频率学派和贝叶斯学派对统计的不同认识。其实，可以简单地把两者联系起来，假设先验分布是均匀分布，取后验概率最大，就能从贝叶斯估计得到极大似然估计。
<p align="center">
        <img src="http://115.159.24.45:3000/statistical_learning/pic/Fig9.png" width="60%"/>
</p>

2. **核方法**

核方法 (kernel method) 是使用核函数表示和学习非线性模型的一种机器学习方法，可以用于监督学习和无监督学习。有一些线性模型的学习方法基于相似度计算，更具体地，向量内积计算。核方法可以把它们扩展到非线性模型的学习，使其应用范围更广泛。

把线性模型扩展到非线性模型，直接的做法是显式地定义从输入空间(低维空间)到特征空间(高维空间)的映射，在特征空间中进行内积计算，比如，支持向量机，把输入空间的线性不可分问题转化为特征空间的线性可分问题。核方法的技巧在于不显式地定义这个映射，而是直接定义核函数，即映射之后在特征空间的内积。这样可以简化计算，达到同样的效果。

假设 $X_1$和$X_2$是输入空间的任意两个实例(向量) ，其内积是 $\left \langle  X_1 ,X_2 \right \rangle$ 。假设从输入空间到特征空间的映射是$\varphi $，于是$ X_1$与$ X_2$ 在特征空间的映像是 $\varphi (X_1)$与$\varphi (X_2)$ ,其内积是$\left \langle \varphi ( X_1) ,\varphi (X_2) \right \rangle$。核方法直接在输入空间中定义核函数 $K(X_1 ,X_2)$ 使其满足$K(X_1 ,X_2)=\left \langle \varphi ( X_1) ,\varphi (X_2) \right \rangle$。

### **1.3&nbsp;&nbsp;统计学习方法的三要素**

统计学习方法都是由模型、策略和算法构成的，即统计学习方法由三要素构成，可以简单地表示为:

$$方法=模型+策略+算法$$

1. **模型**

统计学习首要考虑的问题是学习什么样的模型。在监督学习过程中，模型就是所要学习的条件概率分布或决策函数。模型的假设空间 (hypothesis space) 包含所有可能的条件概率分布或决策函数。例如，假设决策函数是输入变量的线性函数，那么模型的假设空间就是所有这些线性函数构成的函数集合。假设空间中的模型一般有无穷多个。

假设空间用$\mathcal{F} $表示。假设空间可以定义为决策函数的集合:
$$\mathcal{F} = \{f|Y=\textit{f}(X)\}$$
其中，$X$和$Y$是定义在输入空间$\mathcal{X}$和输出空间$\mathcal{Y}$上的变量。这时$\mathcal{F} $通常是由一个参数向量决定的函数族：
$$\mathcal{F}=\{f|Y=\textit{f}_{\theta}(X),\theta \in \mathbf{R}^{n}\}$$

参数向量$\theta$取值于$\textit{n}$维欧氏空间$\mathbf{R}^{n}$称为参数空间 (parameter space)。

假设空间也可以定义为条件概率的集合:
$$\mathcal{F}=\{P|P(Y|X)\}$$
其中，$X$和$Y$是定义在输入空间$\mathcal{X}$和输出空间$\mathcal{Y}$上的变量。这时$\mathcal{F} $通常是由一个参数向量决定的条件概率分布族：
$$\mathcal{F}=\{P|P_{\theta}(Y|X) ,\theta\in \mathbf{R}^{n}\}$$

参数向量$\theta$取值于$\textit{n}$维欧氏空间$\mathbf{R}^{n}$称为参数空间。

2. **策略**

有了模型的假设空间，统计学习接着需要考虑的是按照什么样的准则学习或选择最优的模型。统计学习的目标在于从假设空间中选取最优模型。

首先引入损失函数与风险函数的概念。损失函数度量模型一次预测的好坏，风险函数度量平均意义下模型预测的好坏。


监督学习问题是在假设空间$\mathcal{F}$中选取模型$f$作为决策函数，对于给定的输入$X$ 给出相应的输出$\hat{Y}=f(X)$，这个输出的预测值$f(X)$ 与真实值$Y$可能一致也可能不一致，用 个损失函数(loss function) 或代价函数 (cost function) 来度量预测错误的
程度。损失函数是 $f(X)$和$Y$ 的非负实值函数，记作 $L(Y,f(X))$。


**常见损失函数：**

- 0-1损失函数
$$
L(Y,f(X))=\left\{\begin{matrix}
  1,& Y\ne f(X)\\
  0,& Y=f(X)
\end{matrix}\right. 
$$

- 平方损失函数
$$
L(Y,f(X))=(Y-f(X))^2
$$

- 绝对损失函数
$$
L(Y,f(X))=|Y-f(X)|
$$
- 对数损失函数、对数似然损失函数
$$
L(Y,P(Y|X))=-logP(Y|X)
$$

损失函数值越小，模型就越好。由于模型的输入、输出 $(X,Y)$ 是随机变量，遵循联合分布$P(X,Y)$所以损失函数的期望是:

$$
\mathcal{R}_{exp}(f)=E_P[L(Y,f(X))]\\
=\int _{\mathcal{X}\times \mathcal{Y}}L(y,f(x))P(x,y)dxdy
$$

这是理论上模型 $f(X)$ 关于联合分布 $P(X,Y)$ 的平均意义下的损失，称为风险函数(risk function) 或期望损失 (expected loss)。

学习的目标就是选择期望风险最小的模型。由于联合分布 $P(X,Y)$ 是未知的，$R_{exp}(f)$不能直接计算。实际上，如果知道联合分布$P(X|Y)$可以从联合分布直接求出条件概率分布$P(Y|X)$也就不需要学习了。正因为不知道联合概率分布，所以才需要进行学习。这样一来，一方面根据期望风险最小学习模型要用到联合分布，另一方面联合分布又是未知的，所以监督学习就成为 个病态问题 (ill-formed problem)。

给定一个训练数据集
$$
T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}
$$
模型 $f(X)$ 关于训练数据集的平均损失称为经验风险 (empirical risk) 或经验损
(empirical loss) ，记作 $\mathcal{R}_{emp}$：
$$
\mathcal{R}_{emp}(f)=\frac{1}{N}\sum_{i=1}^{N}L(y_i,f(x_i))  
$$
期望风险$\mathcal{R}_{exp}(f)$是模型关于联合分布的期望损失，经验风险$\mathcal{R}_{emp}(f)$是模型关于训练样本集的平均损失。根据大数定律 当样本容量 趋于无穷时，经验风险$\mathcal{R}_{emp}(f) $趋于期望风险$\mathcal{R}_{exp}(f)$。所以 很自然的想法是用经验风险估计期望风险。
但是，由于现实中训练样本数目有限，甚至很小，所以用经验风险估计期望风险常常井不理想，要对经验风险进行一定的矫正。这就关系到监督学习的两个基本策略：经验风险最小化和结构风险最小化。

- 经验风险最小化
$$
min_{f\in \mathcal{F}} \frac{1}{N}\sum_{i=1}^{N}L(y_i,f(x_i))  
$$

- 结构风险最小化
$$
min_{f\in \mathcal{F}} \frac{1}{N}\sum_{i=1}^{N}L(y_i,f(x_i))+\lambda J(f)
$$

其中 $J(f)$ 为模型的复杂度，模型$f$越复杂，复杂度$J(f)$ 就越大:反之，模型$f$越简单，复杂度$J(f)$就越小。也就是说，复杂度表示了对复杂模型的惩罚。$\lambda$是系数，用以权衡经验风险和模型复杂度，结构风险小需要经验风险与模型复杂度同时小。结构风险小的模型往往对训练数据以及未知的测试数据都有较好的预测。


3. **算法**

- 神经网络的优化器

算法是指学习模型的具体计算方法。统计学习基于训练数据集，根据学习策略，从假设空间中选择最优模型，最后需要考虑用什么样的计算方法求解最优模型。这时，统计学习问题归结为最优化问题，统计学习的算法成为求解最优化问题的
算法。如果最优化问题有显式的解析解，这个最优化问题就比较简单。但通常解析解不存在，这就需要用数值计算的方法求解。如何保证找到全局最优解，并使求解的过程非常高效，就成为一个重要问题。统计学习可以利用己有的最优化算法，有时也需要开发独自的最优化算法。



### **1.4&nbsp;&nbsp;模型评估与模型选择**

|评价|  训练集准确率   | 测试集准确率 |
| :-:   |  :-:    | :-:   |
|欠拟合| 低  | - |
|过拟合|高  | 低 |
|最佳|高  | 高 |

过拟合：当选择的模型复杂度过大时，过拟合现象就会发生。这样，在学习时就要防止过拟合，进行最优的模型选择，即选择复杂度适当的模型，以达到使测试误差最小的学习目的。

### **1.5&nbsp;&nbsp;正则化与交叉验证**

1. **正则化**

模型选择的典型方法是正则化 (regularization) 。正则化是结构风险最小化策略的实现，是在经验风险上加 个正则化项 (regularizer )或罚项 (penalty term) 。正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大。比如，正则化项可以是模型参数向量的范数。

正则化 般具有如下形式:
$$
min_{f\in \mathcal{F}} \frac{1}{N}\sum_{i=1}^{N}L(y_i,f(x_i))+\lambda J(f)
$$

可以取$L_1$范数：

$$
L(\textit{W})= \frac{1}{N}\sum_{i=1}^{N}L(y_i,f(x_i))+\lambda|\textit{W}|
$$

或$L_2$范数：
$$
L(\textit{W})= \frac{1}{N}\sum_{i=1}^{N}L(y_i,f(x_i))+\frac{\lambda}{2}||\textit{W}||^2
$$

正则化符合奥卡姆剃刀 (Occam's razor) 原理。奥卡姆剃刀原理应用于模型选择时变为以下想法:在所有可能选择的模型中，能够很好地解释己知数据并且十分简单才是最好的模型，也就是应该选择的模型。从贝叶斯估计的角度来看，正则化项对于模型的先验概率。可以假设复杂的模型有较小的先验概率，简单的模型有较大的先验概率。

2. **交叉验证**

如果给定的样本数据充足，进行模型选择的 种简单方法是随机地将数据集切分成三部分，分别为训练集(training set) 、验证集 (validation set) 和测试集 (test set) 。训练集用来训练模型，验证集用于模型的选择，而测试集用于最终对学习方法的评估。

- 简单交叉验证

简单交叉验证方法是:首先随机地将己给数据分为两部分，部分作为训练集，另一部分作为测试集(例如，70%的数据为训练集，30% 的数据为测试集)；然后用训练集在各种条件下(例如，不同的参数个数)训练模型，从而得到不同的模型；在测试集上评价各个模型的测试误差，选出测试误差最小的模型。

-  $S$折交叉验证

应用最多的是$S$折交叉验证(S-fold cross validation)，方法如下：首先随机地将已给数据切分为$S$个互不相交、大小相同的子集；然后利用$S-1$个子集的数据训练模型，利用余下的子集测试模型；将这一过程对可能的$S$种选择重复进行；最后选出$S$次评测中平均测试误差最小的模型。

- 留一交叉验证

折交叉验证的特殊情形是$S=N$称为留一交叉验证(Leave-one-out cross validation)，往往在数据缺乏的情况下使用。这里$N$是给定数据集的容量。