# **统计学习方法**
## **第1章&nbsp;&nbsp;统计学习及监督学习概述**

<br>

**导论：**
- 1.1节叙述统计学习或机器学习的定义、研究对象与方法；
- 1.2节叙述统计学习的分类，基本分类是监督学习、无监督学习、强化学习；
- 1.3节叙述统计学习方法的三要素；模型、策略和算法；
- 1.4节至1.7节相继介绍监督学习的几个重要概念，包括模型评估与模型选择、正则化与交叉验证、学习的泛化能力、生成模型与判别模型；
 - 1.8节介绍监督学习的应用：分类问题，标注问题与回归问题。


<p align="center">
        <img src="http://115.159.24.45:3000/statistical_learning/pic/Fig1.png" width="60%"/>
</p>
<p align="center">总体学习框架图</p>


### **1.1&nbsp;&nbsp;统计学习**

#### **1.&nbsp;&nbsp;统计学习特点**
（1）统计学习以计算机及网络为平台，是建立在计算机及网络上的；\
（2）统计学习以数据为研究对象，是数据驱动的学科；\
（3）统计学习的目的是对数据进行预测与分析；\
（4）统计学习以方法为中心，统计学习方法构建模型并应用模型进行预测与分析；\
（5）统计学习是概率论、统计学、信息论、计算理论、最优化理论及计算机科学等多个领域的交叉学科，并且在发展中逐步形成独自的理论体系与方法论。
#### **2.&nbsp;&nbsp;统计学习的对象**
数据。
#### **3.&nbsp;&nbsp;统计学习的目的**
统计学习用于对数据的预测与分析，特别是对**未知新数据**的预测与分析。对数据的预测与分析是通过构建概率统计模型实现的。统计学习总的目标就是考虑学习什么样的模型和如何学习模型，以使模型能对数据进行准确的预测与分析，同时也要考虑尽可能地提高学习效率。
#### **4.&nbsp;&nbsp;统计学习的方法**

统计学习的方法是基于数据构建概率统计模型从而对数据进行预测与分析。统计学习由监督学习（supervised learning）、无监督学习（unsupervised learning）和强化学习（reinforcement learning） 等组成。

统计学习方法可以概括如下：
- 从给定的、有限的、用于学习的训练数据（training data）集合出发，假设数据是独立同分布产生的；
- 并且假设要学习的模型属于某个函数的集合，称为假设空间（hypothesis space）；
- 应用某个评价准则（evaluation criterion），从假设空间中选取一个最优模型，使它对己知的训练数据及未知的测试数（test data）在给定的评价准则下有最优的预测，最优模型的选取由算法实现。
- 这样，统计学习方法包括模型的假设空间、模型选择的准则以及模型学习的算法。称其为统计学习方法的三要素，简称为模型 （model）、策略 （strategy）和算法（algorithm）。

实现统计学习的步骤：
1. 得到一个有限的训练数据集合（训练集）
2. 确定模型的假设空间，也就是所有备选模型（模型结构）
3. 确认模型学习的准则，即学习的策略（**怎么学习，设计cost funtion？**）
4. 实现求解最优模型的算法（**如何求解，优化器？**）
5. 通过学习方法选择最优模型
6. 利用学习的最优模型对新数据进行预测或分析（预测）

### **1.2&nbsp;&nbsp;统计学习的分类**
<p align="center">
        <img src="http://115.159.24.45:3000/statistical_learning/pic/Fig2.png" width="90%"/>
</p>
<p align="center">统计学习的分类总体框架图</p>


#### **1.2.1 基本分类**
1. **监督学习**
> 监督学习 (supervised learning) 是指从标注数据中学习预测模型的机器学习问题。标注数据表示输入输出的对应关系，预测模型对给定的输入产生相应的输出。监督学习的本质是学习输入到输出的映射的统计规律。

- **输入空间与输出空间**
> 在监督学习中，将输入与输出所有可能取值的集合分别称为输入空间 (input space) 与输出空间 (output space) 。输入与输出空间可以是有限元素的集合，也可以是整个欧氏空间。输入空间与输出空间可以是同一个空间，也可以是不同的空间;但通常输出空间远远小于输入空间。

- **特征空间**
> 每个具体的输入是一个实例(instance) ，通常由特征向量 (feature vector) 表示。这时，所有特征向量存在的空间称为特征空间 (feature space) 。特征空间的每一维对应于 个特征。有时假设输入空间与特征空间为相同的空间，对它们不予区分；有时假设输入空间与特征空间为不同的空间，将实例从输入空间映射到特征空间。模型实际上都是定义在特征空间上的。

在监督学习中，将输入与输出看作是定义在输入(特征〉空间与输出空间上的随机变量的取值。输入输出变量用大写字母表示，习惯上输入变量写作$X$输出变量写$Y$。输入输出变量的取值用小写字母表示，输入变量的取值写作$x$输出变量的取值写作$Y$。变量可以是标量或向量，都用相同类型字母表示。除特别声明外，向量均为列向量 。输入实例$x$的特征向量记作

$$x=(x^{(1)},x^{(2)},x^{(3)},...,x^{(n)}) ^T$$

$x^{(i)}$表示$x$的第$i$个特征。注意$x^{(i)}$与$x_i$ 不同，通常用 $x_i$ 表示多个输入变量中的第$i$个变量，即
$$x=(x^{(1)}_i,x^{(2)}_i,x^{(3)}_i,...,x^{(n)}_i) ^T$$

监督学习从训练数据 (training data) 合中学习模型，对测试数据 (test data) 进行预测。训练数据由输入(或特征向量)与输出对组成，训练集通常表示为
$$T=\{(x_1,y_1),(x_1,y_1),(x_1,y_1),...,(x_N,y_N)\}$$
测试数据也由输入与输出对组成 输入与输出对又称为样本 (sample) 或样本点。


监督学习利用训练数据集学习一个模型，再用模型对测试样本集进行预测。由于在这个过程中需要标注的训练数据集，而标注的训练数据集往往是人工给出的 ，所以称为监督学习。监督学习分为学习和预测两个过程，由学习系统与预测系统完成，可用下图表示。
<p align="center">
        <img src="http://115.159.24.45:3000/statistical_learning/pic/Fig3.png" width="50%"/>
</p>

监督学习分为学习和预测两个过程，由学习系统与预测系统完成。在学习过程中，学习系统利用给定的训练数据集，通过学习(或训练)得到一个模型，表示为条件概率分布$\hat{P}(Y|X)$或决策函数$Y=\hat{f}(X)$。条件概率分布$\hat{P}(Y|X)$或决策函数$Y=\hat{f}(X)$描述输入与输出随机变量之间的映射关系。在预测过程中，预测系统对于给定的测试样本集中的输入$x_{N+1}$由模型$y_{N+1}=argmax_y\hat{P}(y|x_{N+1})$或$y_{N+1}=\hat{f}(y|x_{N+1})$给出相应的输出$y_{N+1}$。

2. **无监督学习**

> 无监督学习(unsupervised learning) 是指从无标注数据中学习预测模型的机器学习问题。无标注数据是自然得到的数据，预测模型表示数据的类别、转换或概率。

无监督学习的本质是学习数据中的统计规律或潜在结构。模型的输入与输出的所有可能取值的集合分别称为输入空间与输出空间。输入空间与输出空间可以是有限元素集合，也可以是欧氏空间。每个输入是一个实例，由特征向量表示。每一个输出是对输入的分析结果，由输入的类别、转换或概率表示。模型可以实现对数据的聚类、降维或概率估计。

假设$\chi$是输入空间，$\Zeta$是隐式结构空间 。要学习的模型可以表示为函数$z=g(X)$条件概率分布 $P(z|x)$ 或者条件概率分布 $P(X|z)$ 的形式，其中$x\in\chi$是输入，$$是输出。包含所有可能的模型的集合称为假设空间。无监督学习旨在从假设空间中选出在给定评价标准下的最优模型。