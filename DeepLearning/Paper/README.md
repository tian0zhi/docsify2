

---
# **论文**
---

<!--
模板：

---
---
### Towards a General Purpose CNN for Long Range Dependencies in ND
**简要概述(采用什么样的方法解决了什么样等问题)：** 利用一种连续卷积神经网络解决数据分辨率、维度和长度在不同场景不同——如，信号采样率不同。   \
**摘要：**  卷积神经网络(CNNs)的使用在深度学习中是广泛的，由于一系列理想的模型属性，这导致了一个高效和有效的机器学习框架。然而，性能CNN架构必须针对特定的任务进行定制，必须考虑诸如输入长度、分辨率和维度等因素。在这项工作中，我们通过我们的连续卷积神经网络(CCNN)克服了CNN架构的缺陷，CCNN是一个配有连续卷积核的单一CNN架构，可以用于对任意分辨率、维度和长度的数据的任务，而不需要结构变化。连续卷积核对每一层的长距离依赖进行建模，消除了当前CNN架构中需要的降采样层和任务依赖深度。通过将相同的CCNN应用于一系列序列(1D)和可视化数据(2D)上的任务，我们展示了我们方法的普遍性。我们的CCNN在所有考虑的任务上都表现得很有竞争力，并且经常超过目前最先进的技术。\
**Abstract:**  The use of Convolutional Neural Networks (CNNs) is widespread in Deep Learning due to a range of desirable
model properties which result in an efficient and effective machine learning framework. However, performant CNN
architectures must be tailored to specific tasks in order to incorporate considerations such as the input length, resolution, and dimentionality. In this work, we overcome the need for problem-specific CNN architectures with our
Continuous Convolutional Neural Network (CCNN): a single CNN architecture equipped with continuous convolutional kernels that can be used for tasks on data of arbitrary resolution, dimensionality and length without structural
changes. Continuous convolutional kernels model long range dependencies at every layer, and remove the need
for downsampling layers and task-dependent depths needed in current CNN architectures. We show the generality
of our approach by applying the same CCNN to a wide set of tasks on sequential (1D) and visual data (2D).
Our CCNN performs competitively and often outperforms the current state-of-the-art across all tasks considered.\
[文章源](https://arxiv.org/pdf/2206.03398.pdf) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[本地源](http://115.159.24.45:3000/DeepLearning/Paper/PDF/2206.03398.pdf)
---


-->

## **卷积神经网络**

---
### Towards a General Purpose CNN for Long Range Dependencies in ND
**简要概述(采用什么样的方法解决了什么样等问题)：** 利用一种连续卷积神经网络解决数据分辨率、维度和长度在不同场景不同——如，信号采样率不同。   \
**摘要：**  卷积神经网络(CNNs)的使用在深度学习中是广泛的，由于一系列理想的模型属性，这导致了一个高效和有效的机器学习框架。然而，性能CNN架构必须针对特定的任务进行定制，必须考虑诸如输入长度、分辨率和维度等因素。在这项工作中，我们通过我们的连续卷积神经网络(CCNN)克服了CNN架构的缺陷，CCNN是一个配有连续卷积核的单一CNN架构，可以用于对任意分辨率、维度和长度的数据的任务，而不需要结构变化。连续卷积核对每一层的长距离依赖进行建模，消除了当前CNN架构中需要的降采样层和任务依赖深度。通过将相同的CCNN应用于一系列序列(1D)和可视化数据(2D)上的任务，我们展示了我们方法的普遍性。我们的CCNN在所有考虑的任务上都表现得很有竞争力，并且经常超过目前最先进的技术。\
**Abstract:**  The use of Convolutional Neural Networks (CNNs) is widespread in Deep Learning due to a range of desirable
model properties which result in an efficient and effective machine learning framework. However, performant CNN
architectures must be tailored to specific tasks in order to incorporate considerations such as the input length, resolution, and dimentionality. In this work, we overcome the need for problem-specific CNN architectures with our
Continuous Convolutional Neural Network (CCNN): a single CNN architecture equipped with continuous convolutional kernels that can be used for tasks on data of arbitrary resolution, dimensionality and length without structural
changes. Continuous convolutional kernels model long range dependencies at every layer, and remove the need
for downsampling layers and task-dependent depths needed in current CNN architectures. We show the generality
of our approach by applying the same CCNN to a wide set of tasks on sequential (1D) and visual data (2D).
Our CCNN performs competitively and often outperforms the current state-of-the-art across all tasks considered.\
[文章源](https://arxiv.org/pdf/2206.03398.pdf) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[本地源](http://115.159.24.45:3000/DeepLearning/Paper/PDF/2206.03398.pdf)
---
